{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **üìù MCQ_Test**\n",
        "\n",
        "When designing MCQ exam for a math syllabus, there are several global standards and best practices to ensure that the questions accurately measure the understanding of every concept and maintain fairness for all students. Here‚Äôs a structured approach:\n",
        "\n",
        "### 1. **Blueprint/Content Outline**\n",
        "   - **Define Learning Objectives**: Break down the syllabus into key topics and objectives. Ensure questions cover all key areas, ranging from foundational to advanced concepts.\n",
        "   - **Weightage of Topics**: Distribute questions based on the importance of each topic. For example, if algebra covers 40% of the syllabus, 20 out of 50 questions should focus on algebra.\n",
        "\n",
        "### 2. **Cognitive Levels (Bloom‚Äôs Taxonomy)**\n",
        "   Ensure that the questions assess different cognitive levels:\n",
        "   - **Knowledge/Recall** (e.g., definitions, basic formulae): 20-30%\n",
        "   - **Comprehension/Understanding** (e.g., interpreting graphs, understanding relationships): 20-30%\n",
        "   - **Application** (e.g., solving problems using formulas or concepts): 30-40%\n",
        "   - **Analysis/Evaluation** (e.g., analyzing complex problems, critical thinking): 10-15%\n",
        "\n",
        "   This ensures that the exam measures both basic understanding and higher-order thinking skills.\n",
        "\n",
        "### 3. **Question Construction**\n",
        "   - **Clear and Concise Wording**: Avoid ambiguous language or unnecessarily complex phrasing.\n",
        "   - **Single Concept per Question**: Each question should focus on one key concept to avoid confusion.\n",
        "   - **Avoid Tricky Questions**: The goal is to assess knowledge, not to confuse students with tricky or misleading questions.\n",
        "\n",
        "### 4. **Plausible Distractors (Wrong Options)**\n",
        "   - **Plausible Distractors**: Incorrect answers should be reasonable but clearly wrong if the student knows the concept. This challenges students without being unfair.\n",
        "   - **Avoid ‚ÄúAll of the Above‚Äù or ‚ÄúNone of the Above‚Äù**: These options can sometimes skew the assessment if used improperly. Use them sparingly.\n",
        "\n",
        "### 5. **Difficulty Levels**\n",
        "   - **Balanced Difficulty**: Distribute questions across easy (30%), moderate (50%), and difficult (20%) levels. This helps in differentiating student performance while ensuring that most students can answer a significant portion of the exam.\n",
        "\n",
        "### 6. **Randomization and Fairness**\n",
        "   - **Avoid Patterned Answers**: Ensure that the correct answers are randomly distributed (e.g., avoid too many consecutive \"B\" answers).\n",
        "   - **Shuffling**: If delivering the exam digitally, shuffle questions to minimize the chances of students copying answers.\n",
        "\n",
        "### 7. **Cultural and Gender Sensitivity**\n",
        "   - Ensure that the content of the questions does not favor any cultural or gender group. Math questions should remain neutral and universally applicable.\n",
        "\n",
        "### 8. **Time Management**\n",
        "   - **Appropriate Timing**: Each question should be solvable within a set time frame, based on the complexity of the syllabus. Typically, allow 1-2 minutes per question depending on the difficulty, making sure students can reasonably complete the exam within the allotted time.\n",
        "\n",
        "### 9. **Review and Validation**\n",
        "   - **Peer Review**: Have other teachers or subject matter experts review the questions for clarity, relevance, and fairness.\n",
        "   - **Pilot Testing**: Consider running a small pilot test or review with a group of students to identify any issues with question clarity or difficulty distribution.\n",
        "\n",
        "### 10. **Scoring and Feedback**\n",
        "   - **Equal Weighting**: Ensure each question carries equal marks unless specific questions are designed to carry more weight.\n",
        "   - **Detailed Feedback**: Provide feedback on wrong answers, explaining the correct solution or directing students to relevant material to enhance learning post-exam.\n",
        "\n",
        "These standards help create a comprehensive, fair, and effective MCQ exam that assesses students' mastery of the math syllabus and ensures an equitable testing environment."
      ],
      "metadata": {
        "id": "Lp0RVfZc_cGY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmZIjM39-xBP"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install PyPDF2\n",
        "!pip install -U -q \"google-generativeai>=0.7.2\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import PyPDF2\n",
        "import re\n",
        "import time\n",
        "from openai import OpenAI\n",
        "import html\n",
        "from IPython.display import display, Markdown, HTML\n",
        "import google.generativeai as genai\n",
        "from IPython.display import Markdown\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "g1Sh1cIR_MV_"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "Markdown(f\"##Current used device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "ccgFIq8m_zaq",
        "outputId": "d69bac6a-cdca-43ad-e245-0c09509b1916"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "##Current used device: cpu"
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PDF_PATH        = '/content/calculus_contents.pdf'\n",
        "GPT_KEY_PATH    = '/content/key.txt'\n",
        "GEMINI_KEY_PATH = '/content/key2.txt'\n",
        "EXAM_PATH       = '/content/exam.txt'"
      ],
      "metadata": {
        "id": "3ZTjSuPtLNcD"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_pdf_text(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        text = ''\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            text += page.extract_text()\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "# Extract the text from the PDF\n",
        "pdf_content = extract_pdf_text(PDF_PATH)"
      ],
      "metadata": {
        "id": "cOOUbk2ALROq"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(EXAM_PATH, 'r') as file:\n",
        "    EXM = file.read()\n",
        "\n",
        "with open(GPT_KEY_PATH, 'r') as file:\n",
        "    GPT = file.read()\n",
        "\n",
        "with open(GEMINI_KEY_PATH, 'r') as file:\n",
        "    GEM = file.read()\n",
        "\n",
        "GPT_API_KEY    = f\"{GPT}\"\n",
        "GEMINI_API_KEY = f\"{GEM}\"\n",
        "exam           = f\"{EXM}\""
      ],
      "metadata": {
        "id": "FTr2D_JFAAea"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    api_key = GPT_API_KEY\n",
        ")\n",
        "\n",
        "genai.configure(api_key = GEMINI_API_KEY)"
      ],
      "metadata": {
        "id": "v0vCWHQ1BCbn"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_MODEL = \"gpt-4o\"\n",
        "GEMINI_MODEL = \"gemini-1.5-pro\"\n",
        "\n",
        "MAX_TOKENS = 3000\n",
        "TEMP = 0.2"
      ],
      "metadata": {
        "id": "HEBwWTi0DpAx"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_instructions = \"\"\"\n",
        "          You are an expert AI assistant with advanced reasoning capabilities. Your task is to provide detailed, step-by-step explanations of your thought process. For each step:\n",
        "\n",
        "          1. Provide a clear, concise title describing the current reasoning phase.\n",
        "          2. Elaborate on your thought process in the content section.\n",
        "          3. Decide whether to continue reasoning or provide a final answer.\n",
        "\n",
        "          Key Instructions:\n",
        "          - Employ at least 5 distinct reasoning steps.\n",
        "          - Acknowledge your limitations as an AI and explicitly state what you can and cannot do.\n",
        "          - Actively explore and evaluate alternative answers or approaches.\n",
        "          - Critically assess your own reasoning; identify potential flaws or biases.\n",
        "          - When re-examining, employ a fundamentally different approach or perspective.\n",
        "          - Utilize at least 3 diverse methods to derive or verify your answer.\n",
        "          - Incorporate relevant domain knowledge and best practices in your reasoning.\n",
        "          - Quantify certainty levels for each step and the final conclusion when applicable.\n",
        "          - Consider potential edge cases or exceptions to your reasoning.\n",
        "          - Provide clear justifications for eliminating alternative hypotheses.\n",
        "\n",
        "          Don't include the thougts steps with your response\n",
        "\n",
        "          \"\"\"\n",
        "\n",
        "assistant_instructions = \"I will think step by step following my instructions, starting at the beginning after decomposing the problem.\""
      ],
      "metadata": {
        "id": "V3AyvlilsxQB"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response_gpt(model, tokens, temp, prompt):\n",
        "  return client.chat.completions.create(\n",
        "\n",
        "      model = model,\n",
        "      max_tokens = tokens,\n",
        "      temperature = temp,\n",
        "\n",
        "      messages=[\n",
        "        {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": system_instructions\n",
        "        },\n",
        "\n",
        "        {\n",
        "          \"role\" : \"user\",\n",
        "          \"content\" : prompt\n",
        "        },\n",
        "\n",
        "        {\n",
        "          \"role\" : \"assistant\",\n",
        "          \"content\" : system_instructions\n",
        "        }\n",
        "      ]\n",
        "  )"
      ],
      "metadata": {
        "id": "HNW0y3VpCA9l"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response_gemini(tokens, temp):\n",
        "  return genai.GenerativeModel(\n",
        "      model_name = GEMINI_MODEL,\n",
        "      generation_config = {\n",
        "          \"temperature\": temp,\n",
        "          # \"tokens\": tokens\n",
        "      },\n",
        "      system_instruction = system_instructions\n",
        "  )"
      ],
      "metadata": {
        "id": "-Txx3825hzNC"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "syllabus_prompt = f\"rewrite this text with meaningful data: {pdf_content}\"\n",
        "\n",
        "syllabus = generate_response_gpt(GPT_MODEL, MAX_TOKENS, TEMP, syllabus_prompt).choices[0].message.content"
      ],
      "metadata": {
        "id": "hwvSyguyL-t-"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_questions = 10\n",
        "\n",
        "prompt = f\"\"\"\n",
        "As an expert mathematics teacher you will be given MCQ exam consists of {n_questions} number of questions and their choices, your task is to evaluate the questions of it step by step and using advanced reasoning,\n",
        "Your final evaluation will be out of 10 points score based on this criteria:\n",
        "\n",
        "1. Blueprint/Content Outline\n",
        "    Define Learning Objectives: Break down the syllabus into key topics and objectives. Ensure questions cover all key areas, ranging from foundational to advanced concepts.\n",
        "    Weightage of Topics: Distribute questions based on the importance of each topic. For example, if algebra covers 40% of the syllabus, 20 out of 50 questions should focus on algebra.\n",
        "\n",
        "2. Cognitive Levels (Bloom‚Äôs Taxonomy)\n",
        "  Ensure that the questions assess different cognitive levels:\n",
        "    Knowledge/Recall (e.g., definitions, basic formulae): 20-30%\n",
        "    Comprehension/Understanding (e.g., interpreting graphs, understanding relationships): 20-30%\n",
        "    Application (e.g., solving problems using formulas or concepts): 30-40%\n",
        "    Analysis/Evaluation (e.g., analyzing complex problems, critical thinking): 10-15%\n",
        "  ensures that the exam measures both basic understanding and higher-order thinking skills.\n",
        "\n",
        "3. Question Construction\n",
        "    Clear and Concise Wording: Avoid ambiguous language or unnecessarily complex phrasing.\n",
        "    Single Concept per Question: Each question should focus on one key concept to avoid confusion.\n",
        "    Avoid Tricky Questions: The goal is to assess knowledge, not to confuse students with tricky or misleading questions.\n",
        "\n",
        "4. Plausible Distractors (Wrong Options)\n",
        "    Plausible Distractors: Incorrect answers should be reasonable but clearly wrong if the student knows the concept. This challenges students without being unfair.\n",
        "    Avoiding ‚ÄúAll of the Above‚Äù or ‚ÄúNone of the Above‚Äù: These options can sometimes skew the assessment if used improperly. Use them sparingly.\n",
        "\n",
        "5. Difficulty Levels\n",
        "    Balanced Difficulty: Distribute questions across easy (30%), moderate (50%), and difficult (20%) levels. This helps in differentiating student performance while ensuring that most students can answer a significant portion of the exam.\n",
        "\n",
        "6. Randomization and Fairness\n",
        "    Avoid Patterned Answers: Ensure that the correct answers are randomly distributed (e.g., avoid too many consecutive \"B\" answers).\n",
        "    Shuffling: If delivering the exam digitally, shuffle questions to minimize the chances of students copying answers.\n",
        "\n",
        "7. Cultural and Gender Sensitivity\n",
        "    Ensure that the content of the questions does not favor any cultural or gender group. Math questions should remain neutral and universally applicable.\n",
        "\n",
        "8. Time Management\n",
        "    Appropriate Timing: Each question should be solvable within a set time frame, based on the complexity of the syllabus. Typically, allow 1-2 minutes per question depending on the difficulty, making sure students can reasonably complete the exam within the allotted time.\n",
        "\n",
        "Here's the syllabus: {syllabus}\n",
        "\n",
        "Here's the exam to be evaluated : {exam}\n",
        "\n",
        "add a highlighted final response number showing the final score from 0 to 10\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "sbkrcxW2EEcB"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate content using the GPT model\n",
        "gpt_response = generate_response_gpt(GPT_MODEL, MAX_TOKENS, TEMP, prompt).choices[0].message.content"
      ],
      "metadata": {
        "id": "7kdg-v3SDWmk"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate content using the Gemini model\n",
        "gemini_response = generate_response_gemini(MAX_TOKENS, TEMP).generate_content(prompt).text"
      ],
      "metadata": {
        "id": "-MlYCjUg0m1N"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the GPT response\n",
        "display(Markdown(\"# GPT Evaluation:\"))\n",
        "display(Markdown(gpt_response))\n",
        "\n",
        "# Display the Gemini response\n",
        "display(Markdown(\"# Gemini Evaluation:\"))\n",
        "display(Markdown(gemini_response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "id": "pu219pf6wB6n",
        "outputId": "43dda017-90b8-47bd-8d1c-10cca3d94689"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# GPT Evaluation:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**1. Blueprint/Content Outline Evaluation**\n\nThe exam consists of 10 questions, and the syllabus covers four main areas: Differentiation and Its Applications, The Calculus of Exponential and Logarithmic Functions, Behaviors of Functions and Curve Sketching, and The Definite Integral and Its Applications. Each area is represented in the exam, ensuring coverage of key topics. However, the distribution is not perfectly aligned with the syllabus weightage. For example, differentiation has a significant presence, but integration and curve sketching are underrepresented. This could lead to an imbalance in assessing students' understanding across all topics.\n\n**2. Cognitive Levels (Bloom‚Äôs Taxonomy) Evaluation**\n\nThe exam questions cover various cognitive levels. Questions 1, 2, 3, 6, and 7 assess knowledge and comprehension, focusing on basic differentiation and integration skills. Questions 4, 5, 8, and 9 require application and analysis, involving problem-solving and critical thinking. However, there is a lack of questions that challenge students at the evaluation level, such as analyzing complex problems or making judgments based on criteria. This limits the exam's ability to assess higher-order thinking skills comprehensively.\n\n**3. Question Construction Evaluation**\n\nThe questions are generally clear and concise, with each focusing on a single concept. For example, Question 1 asks for the derivative of a trigonometric function, and Question 5 involves related rates. However, some questions, like Question 8, could be more explicit in their wording to avoid confusion. Additionally, there are no tricky questions, which aligns with best practices in question construction.\n\n**4. Plausible Distractors Evaluation**\n\nThe distractors in the exam are plausible and challenge students' understanding without being unfair. For instance, in Question 1, the distractors are common misconceptions about derivatives of trigonometric functions. However, the exam could benefit from avoiding options like \"None of the Above\" or \"All of the Above,\" which are not present but should be noted for future exams.\n\n**5. Difficulty Levels Evaluation**\n\nThe exam has a balanced difficulty distribution, with questions ranging from easy (e.g., Question 3) to moderate (e.g., Question 6) and difficult (e.g., Question 9). This distribution helps differentiate student performance while ensuring that most students can answer a significant portion of the exam. However, the exam could include more challenging questions to better assess students' mastery of advanced concepts.\n\n**6. Randomization and Fairness Evaluation**\n\nThe correct answers are randomly distributed, avoiding any discernible patterns. This reduces the likelihood of students guessing answers based on patterns. Additionally, the exam is fair, with no cultural or gender biases present in the questions. The mathematical content is universally applicable, ensuring fairness for all students.\n\n**7. Time Management Evaluation**\n\nThe exam is designed to be completed within a reasonable time frame, with each question solvable within 1-2 minutes. This allows students to complete the exam within the allotted time, assuming they have a good understanding of the material. However, the time allocation could be adjusted for more complex questions to ensure students have enough time to think critically.\n\n**Final Score Evaluation**\n\nBased on the evaluation criteria, the exam scores 8 out of 10 points. The exam effectively covers the syllabus and assesses various cognitive levels, but it could improve in distributing questions according to topic weightage and including more higher-order thinking questions. Additionally, some questions could be more explicit in their wording to avoid confusion. Overall, the exam is well-constructed and fair, providing a good assessment of students' understanding of calculus concepts.\n\n**Final Score: 8/10**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Gemini Evaluation:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Final Response: The Calculus MCQ exam receives a score of **7/10**. \n\nWhile the exam demonstrates some strengths, there are areas for improvement to enhance its alignment with the syllabus and assessment best practices. \n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}