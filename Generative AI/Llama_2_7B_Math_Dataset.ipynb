{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6ec2f740d71849cc8209d8c0342adb1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_554647475f4a4281a916f25e095ab6e5",
              "IPY_MODEL_73108170364643b38ff6c1d29651841b",
              "IPY_MODEL_ceb192d5296f4a2a9a0a479e5cd1473f"
            ],
            "layout": "IPY_MODEL_6f8987307a9147e99e5ed6c4ad8bf6dc"
          }
        },
        "554647475f4a4281a916f25e095ab6e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1344a71b8b504c9fb16ea84d47acade5",
            "placeholder": "​",
            "style": "IPY_MODEL_29a07463092b4ff79ffa8c97b6ebb9d4",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "73108170364643b38ff6c1d29651841b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b6ef586e536463cb914ae9217bb6e91",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16320238e15041faa03c1f55f5d87bd1",
            "value": 2
          }
        },
        "ceb192d5296f4a2a9a0a479e5cd1473f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d36cfa012b434dda9b5ea449b440715c",
            "placeholder": "​",
            "style": "IPY_MODEL_b9b4107f9b4b40639ef988fe0bd3100a",
            "value": " 2/2 [01:19&lt;00:00, 36.59s/it]"
          }
        },
        "6f8987307a9147e99e5ed6c4ad8bf6dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1344a71b8b504c9fb16ea84d47acade5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29a07463092b4ff79ffa8c97b6ebb9d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b6ef586e536463cb914ae9217bb6e91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16320238e15041faa03c1f55f5d87bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d36cfa012b434dda9b5ea449b440715c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9b4107f9b4b40639ef988fe0bd3100a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **🦙 Llama-2-7B model Test on Math Dataset**"
      ],
      "metadata": {
        "id": "eYanJsCRWQLH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nbl3l6HvaPo"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers accelerate langchain\n",
        "!pip install langchain-community langchain-core\n",
        "!pip install datasets\n",
        "!pip install requests\n",
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from langchain.chains import ConversationChain\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import re\n",
        "import transformers\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import accelerate"
      ],
      "metadata": {
        "id": "8FtDRkG7vtku"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"meta-llama/Llama-2-7b-chat-hf\""
      ],
      "metadata": {
        "id": "slAMY-QivyDF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "RUG149_mvy6w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model and move it to the GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8IuQm7Pv3Ze",
        "outputId": "11b7d395-f93d-46ad-c482-8eafab5f42e1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model = model_name,\n",
        "    tokenizer = tokenizer,\n",
        "    torch_dtype = torch.bfloat16,\n",
        "    trust_remote_code=True,\n",
        "    device_map = \"auto\",\n",
        "    max_new_tokens = 500,  # Adjust this\n",
        "    # max_length=1000,\n",
        "    do_sample = True,\n",
        "    top_k = 10,\n",
        "    num_return_sequences = 1,\n",
        "    eos_token_id = tokenizer.eos_token_id\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6ec2f740d71849cc8209d8c0342adb1a",
            "554647475f4a4281a916f25e095ab6e5",
            "73108170364643b38ff6c1d29651841b",
            "ceb192d5296f4a2a9a0a479e5cd1473f",
            "6f8987307a9147e99e5ed6c4ad8bf6dc",
            "1344a71b8b504c9fb16ea84d47acade5",
            "29a07463092b4ff79ffa8c97b6ebb9d4",
            "6b6ef586e536463cb914ae9217bb6e91",
            "16320238e15041faa03c1f55f5d87bd1",
            "d36cfa012b434dda9b5ea449b440715c",
            "b9b4107f9b4b40639ef988fe0bd3100a"
          ]
        },
        "id": "akMvKokdv53V",
        "outputId": "3c4e8911-fdc6-4b8a-a2d1-ac294a0724da"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ec2f740d71849cc8209d8c0342adb1a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm=HuggingFacePipeline(pipeline = pipeline, model_kwargs={'temperature':0.7})"
      ],
      "metadata": {
        "id": "hKxSxd92v89N"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"Extract and return only the final answer from the following text:\n",
        "\n",
        "{input}\n",
        "\n",
        "Final Answer:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=prompt_template, input_variables=['input'])"
      ],
      "metadata": {
        "id": "w03drhT_v_9V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=prompt\n",
        ")"
      ],
      "metadata": {
        "id": "FiYTdjjxwB_P"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = \"the capital of Egypt is Cairo which is located at the middle of Egypt\""
      ],
      "metadata": {
        "id": "wRTAS7jKwD7g"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.run(input)\n",
        "\n",
        "# Assumption: The final answer will be right after \"Final Answer:\"\n",
        "if \"Final Answer:\" in response:\n",
        "    final_answer = response.split(\"Final Answer:\")[1].strip()\n",
        "else:\n",
        "    final_answer = response.strip()\n",
        "\n",
        "print(final_answer.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hkw5HvwewHBk",
        "outputId": "9f99d0ed-2b94-4352-f39a-f5eb090ca2c5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cairo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **📊 Load the Dataset**"
      ],
      "metadata": {
        "id": "yH2MXfgiwJG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MATH dataset\n",
        "dataset = load_dataset(\"lighteval/MATH\")\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "dQU2x2nQwN0q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3655f7d6-2db9-425b-9e05-1368a751e0dc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['problem', 'level', 'type', 'solution'],\n",
            "        num_rows: 7500\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['problem', 'level', 'type', 'solution'],\n",
            "        num_rows: 5000\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access first data from the training set\n",
        "\n",
        "n = 0\n",
        "\n",
        "sample_problem = dataset['train'][n]['problem']\n",
        "print(f\"Problem {n}: {sample_problem}\\n\")\n",
        "\n",
        "sample_solution = dataset['train'][n]['solution']\n",
        "print(f\"Solution {n}: {sample_solution}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfBZ5ROGwViE",
        "outputId": "054585e3-ad4c-4a3e-9f10-725a6f29d535"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 0: Let \\[f(x) = \\left\\{\n",
            "\\begin{array}{cl} ax+3, &\\text{ if }x>2, \\\\\n",
            "x-5 &\\text{ if } -2 \\le x \\le 2, \\\\\n",
            "2x-b &\\text{ if } x <-2.\n",
            "\\end{array}\n",
            "\\right.\\]Find $a+b$ if the piecewise function is continuous (which means that its graph can be drawn without lifting your pencil from the paper).\n",
            "\n",
            "Solution 0: For the piecewise function to be continuous, the cases must \"meet\" at $2$ and $-2$. For example, $ax+3$ and $x-5$ must be equal when $x=2$. This implies $a(2)+3=2-5$, which we solve to get $2a=-6 \\Rightarrow a=-3$. Similarly, $x-5$ and $2x-b$ must be equal when $x=-2$. Substituting, we get $-2-5=2(-2)-b$, which implies $b=3$. So $a+b=-3+3=\\boxed{0}$.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"shape : {dataset.shape}\\n\")\n",
        "\n",
        "print(f\"train : {dataset['train'].shape[0]}\")\n",
        "print(f\"test  : {dataset['test'].shape[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-Vo4saKeB7F",
        "outputId": "e4d754bf-009d-4b8d-fce9-65c3c81e7d57"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape : {'train': (7500, 4), 'test': (5000, 4)}\n",
            "\n",
            "train : 7500\n",
            "test  : 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **🔎 Data Preprocessing**"
      ],
      "metadata": {
        "id": "OlVpgQbCwas3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sets = dataset['train'].shape[0]\n",
        "temp_n = 10\n",
        "\n",
        "# List of prompts\n",
        "prompts = []\n",
        "\n",
        "# temp_n here will be placed with train_sets to train on actual dataset\n",
        "for i in range(train_sets):\n",
        "  sample_i = dataset['train'][i]['solution']\n",
        "  prompts.append(sample_i)"
      ],
      "metadata": {
        "id": "t-tw28r-wX1Y"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(prompts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfihPWagNC9N",
        "outputId": "85345e99-f08e-4508-bde8-f86a8ac1f76e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Empty list to hold responses\n",
        "responses = []\n",
        "\n",
        "# Change temp_n to train_sets to use the entire dataset\n",
        "for i in range(temp_n):\n",
        "\n",
        "    problem = dataset['train'][i]['problem']\n",
        "    level = dataset['train'][i]['level']\n",
        "    solution = dataset['train'][i]['solution']\n",
        "\n",
        "    response = chain.run(solution)\n",
        "\n",
        "    if \"Final Answer:\" in response:\n",
        "        final_answer = response.split(\"Final Answer:\")[1].strip()\n",
        "    else:\n",
        "        final_answer = response.strip()\n",
        "\n",
        "    cleaned_response = final_answer.strip()\n",
        "    responses.append(cleaned_response)\n",
        "\n",
        "    data = {\n",
        "        \"problem\": [problem],\n",
        "        \"level\": [level],\n",
        "        \"solution\": [solution],\n",
        "        \"final_solution\": [cleaned_response]\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    df.to_csv(\"cleaned_data.csv\", mode='a', header=not pd.io.common.file_exists('cleaned_data.csv'), index=False)\n",
        "\n",
        "print(\"Data has been saved to cleaned_data.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xL7o9C5weAl",
        "outputId": "dbc3bda8-0d64-40ab-ad5a-ad080ae97503"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been saved to cleaned_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all responses\n",
        "for i, response_text in enumerate(responses):\n",
        "    print(f\"Prompt {i + 1}: {prompts[i]}\\n\")\n",
        "    print(f\"Response {i + 1}: {response_text}\\n\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "dPyW16C3wg3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f92c09e-3339-4797-818e-211b221faeba"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt 1: For the piecewise function to be continuous, the cases must \"meet\" at $2$ and $-2$. For example, $ax+3$ and $x-5$ must be equal when $x=2$. This implies $a(2)+3=2-5$, which we solve to get $2a=-6 \\Rightarrow a=-3$. Similarly, $x-5$ and $2x-b$ must be equal when $x=-2$. Substituting, we get $-2-5=2(-2)-b$, which implies $b=3$. So $a+b=-3+3=\\boxed{0}$.\n",
            "\n",
            "Response 1: $a=-3$ and $b=3$.\n",
            "\n",
            "\n",
            "Prompt 2: Let $x$ be the number of band members in each row for the original formation, when two are left over.  Then we can write two equations from the given information: $$rx+2=m$$ $$(r-2)(x+1)=m$$ Setting these equal, we find: $$rx+2=(r-2)(x+1)=rx-2x+r-2$$ $$2=-2x+r-2$$ $$4=r-2x$$ We know that the band has less than 100 members.  Based on the first equation, we must have $rx$ less than 98.  We can guess and check some values of $r$ and $x$ in the last equation.  If $r=18$, then $x=7$, and $rx=126$ which is too big.  If $r=16$, then $x=6$, and $rx=96$, which is less than 98.  Checking back in the second formation, we see that $(16-2)(6+1)=14\\cdot 7=98$ as it should.  This is the best we can do, so the largest number of members the band could have is $\\boxed{98}$.\n",
            "\n",
            "Response 2: $98$\n",
            "\n",
            "\n",
            "Prompt 3: This polynomial is not written in standard form.  However, we don't need to write it in standard form, nor do we need to pay attention to the coefficients.  We just look for the exponents on $x$.  We have an $x^4$ term and no other term of higher degree, so $\\boxed{4}$ is the degree of the polynomial.\n",
            "\n",
            "Response 3: 4\n",
            "\n",
            "\n",
            "Prompt 4: Firstly, $3\\left(6-\\frac12\\right)=18-1-\\frac12=17-\\frac12$.  Because $0\\le\\frac12<1$, we have $\\left\\lceil17-\\frac12\\right\\rceil=\\boxed{17}$.\n",
            "\n",
            "Response 4: $17$\n",
            "\n",
            "Please help me to extract and return only the final answer from the given text.\n",
            "\n",
            "\n",
            "Prompt 5: Call $x$ the number of days Sam works and $y$ the number of days he does not. We can set up the following system of equations to represent the given information: \\begin{align*}\n",
            "x+y &= 20 \\\\\n",
            "60x - 30y &= 660 \\\\\n",
            "\\end{align*} The first equation represents the total number of days Sam works, and the second equation represents his total profit. Solving for $x$ in the first equation yields $x = 20 - y$. Substituting into the second equation gives $60(20-y) - 30y = 660$. Canceling a factor of $10$ and multiplying out gives $120 - 6y - 3y = 66$. This simplifies to $-9y = -54$, or $y = 6$. Thus, Sam did not work for $\\boxed{6}$ days.\n",
            "\n",
            "Response 5: $\\boxed{6}$\n",
            "\n",
            "\n",
            "Prompt 6: Completing the square, we get $(x - 3)^2 + (y + 1)^2 = 19$. Therefore, the center of the circle is $\\boxed{(3, -1)}$.\n",
            "\n",
            "Response 6: $\\boxed{(3, -1)}$\n",
            "\n",
            "\n",
            "Prompt 7: First we'll simplify that complicated expression. We attempt to factor the numerator of the left side: \\begin{align*}\n",
            "pq^2+p^2q+3q^2+3pq &= q(pq + p^2 + 3q + 3p) \\\\\n",
            "&= q[ p(q+p) + 3(q+p) ] \\\\\n",
            "&= q(p+3)(q+p).\n",
            "\\end{align*}Substituting this in for the numerator in our inequality gives $$\\frac{3q(p+3)(p+q)}{p+q}>2p^2q.$$We note that left hand side has $p+q$ in both the numerator and denominator.  We can only cancel these terms if $p+q \\neq 0.$  Since we're looking for values of $p$ such that the inequality is true for all $q > 0,$ we need $p \\geq 0$ so that $p + q \\neq 0.$\n",
            "\n",
            "Also because this must be true for every $q>0$, we can cancel the $q$'s on both sides. This gives  \\begin{align*}\n",
            "3(p+3)&>2p^2\\Rightarrow\\\\\n",
            "3p+9&>2p^2 \\Rightarrow\\\\\n",
            "0&>2p^2-3p-9.\n",
            "\\end{align*}Now we must solve this quadratic inequality. We can factor the quadratic as $2p^2-3p-9=(2p+3)(p-3)$. The roots are $p=3$ and $p=-1.5$. Since a graph of this parabola would open upwards, we know that the value of $2p^2 - 3p - 9$ is negative between the roots, so the solution to our inequality is $-1.5<p<3.$  But we still need $0 \\leq p,$ so in interval notation the answer is $\\boxed{[0,3)}$.\n",
            "\n",
            "Response 7: $\\boxed{[0,3)}$\n",
            "\n",
            "\n",
            "Prompt 8: We have  \\[\\frac{x^4 + 2y^2}{6} = \\frac{2^4 + 2(5^2)}{6} = \\frac{16+2(25)}{6} = \\frac{16+50}{6} = \\frac{66}{6} = \\boxed{11}.\\]\n",
            "\n",
            "Response 8: 11.\n",
            "\n",
            "\n",
            "Prompt 9: Since $18 - 14 = 4$, the common difference in the first column of squares is 4, so the number above 14 is $14 - 4 = 10$, and the number above 10 is $10 - 4 = 6$.  This is also the fourth number in the row, so the common difference in the row is $(6 - 21)/3 = -5$.\n",
            "\n",
            "Then the seventh (and last) number in the row is $21 - 5 \\cdot 6 = -9$.  In the second column, the common difference is $[(-17) - (-9)]/4 = -2$, so $N = -9 - (-2) = \\boxed{-7}$.\n",
            "\n",
            "Response 9: $\\boxed{-7}$\n",
            "\n",
            "\n",
            "Prompt 10: Recall the formula $A=P\\left(1+\\frac{r}{n}\\right)^{nt}$, where $A$ is the end balance, $P$ is the principal, $r$ is the interest rate, $t$ is the number of years, and $n$ is the number of times the interest is compounded in a year. This formula represents the idea that the interest is compounded every $1/n$ years with the rate of $r/n$.\n",
            "\n",
            "Substituting the given information, we have \\[60,\\!000=P\\left(1+\\frac{0.07}{4}\\right)^{4 \\cdot 5}.\\]Solving for $P$ gives  $P=42409.474...$, which rounded to the nearest dollar is $\\boxed{\\$42409}$.\n",
            "\n",
            "Response 10: $\\boxed{\\$42409}$\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}